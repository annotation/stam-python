{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e63604b",
   "metadata": {},
   "source": [
    "# STAM Tutorial: Standoff Text Annotation for Pythonistas\n",
    "\n",
    "## Introduction\n",
    "\n",
    "[STAM](https://github.com/annotation/stam) is a data model for stand-off text\n",
    "annotation that allows researchers and developers to model annotations on text.\n",
    "\n",
    "An *annotation* is any kind of remark, classification/tagging on any particular\n",
    "portion(s) of a text, on the resource or annotation set as a whole, in which\n",
    "case we can interpret annotations as *metadata*, or on another annotation\n",
    "(*higher-order annotation*).\n",
    "\n",
    "Examples of annotation may be linguistic annotation, structure/layout\n",
    "annotation, editorial annotation, technical annotation, or whatever comes to\n",
    "mind.STAM define any vocabularies whatsoever. Instead, it provides a\n",
    "framework upon which you can model your annotations using whatever\n",
    "you see fit.\n",
    "\n",
    "The model is thoroughly explained [in its specification\n",
    "document](https://github.com/annotation/stam/blob/master/README.md). We\n",
    "summarize only the most important data structures here, these have direct\n",
    "counterparts (classes) in the python library we will be teaching in this\n",
    "tutorial: \n",
    "\n",
    "* `Annotation`  - A instance of annotation. Associated with an annotation is a\n",
    "  `Selector` to select the target of the annotation, and one or more\n",
    "  `AnnotationData` instances that hold the *body* or *content* of the\n",
    "  annotation. This is explicitly decoupled from the annotation instance itself\n",
    "  as multiple annotations may hold the very same content.\n",
    "* `Selector` - A selector identifies the target of an annotation and the part of the target that the annotation applies to. There are multiple types that are described [here](https://github.com/annotation/stam/blob/master/README.md#class-selector). The `TextSelector` is an important one that selects a target resource and a specific text selection within it by specifying an offset. \n",
    "* `AnnotationData` - A key/value pair that acts as *body* or *content* for one or more annotations. The key is a reference to `DataKey`, the value is a `DataValue`. (The term *feature* is also seen for this in certain annotation paradigms)\n",
    "* `DataKey` - A key as referenced by `AnnotationData`.\n",
    "* `DataValue` - A value with some type information (e.g. string, integer, float).\n",
    "* `TextResource` - A textual resource that is made available for annotation. This holds the actual textual content.\n",
    "* `TextSelection` - A particular selection of text within a resource, i.e. a subslice of the text.\n",
    "* `AnnotationDataSet` - An Annotation Data Set stores the keys (`DataKey`) and\n",
    "  values (`AnnotationData`) that are used by annotations. It effectively\n",
    "  defines a certain vocabulary, i.e. key/value pairs. How broad or narrow the\n",
    "  scope of the vocabulary is not defined by STAM but entirely up to the user. \n",
    "* `AnnotationStore` - The annotation store is essentially your *workspace*, it holds all\n",
    "  resources, annotation sets (i.e. keys and annotation data) and of course the\n",
    "  actual annotations. In the Python implementation it is a memory-based store\n",
    "  and you can put as much as you like into it (as long as it fits in memory).\n",
    "\n",
    "STAM is more than just a theoretical model, we offer practical implementations\n",
    "that allow you to work with it directly. In this tutorial we will be using Python and\n",
    "the Python library `stam`.\n",
    "\n",
    "**Note**: The STAM Python library is a so-called Python binding to a STAM library\n",
    "written in Rust. This means the library is not written in Python but is\n",
    "compiled to machine code and as such offers much better performance.\n",
    "\n",
    "## Installation\n",
    "\n",
    "First of all, you will need to install the STAM Python library from the [Python Package Index](https://pypi.org/project/stam/) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7963c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stam in ./env/lib/python3.10/site-packages (0.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install stam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b423bd0c",
   "metadata": {},
   "source": [
    "## Annotating from scratch\n",
    "\n",
    "### Adding a text\n",
    "\n",
    "Let us start with a mini corpus consisting of two quotes from the book *\"Consider Phlebas\"* by renowned sci-fi author Iain M. Banks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75113e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "# Consider Phlebas\n",
    "$ author=Iain M. Banks\n",
    "\n",
    "## 1\n",
    "Everything about us,\n",
    "everything around us,\n",
    "everything we know [and can know of] is composed ultimately of patterns of nothing;\n",
    "thatâ€™s the bottom line, the final truth.\n",
    "\n",
    "So where we find we have any control over those patterns,\n",
    "why not make the most elegant ones, the most enjoyable and good ones,\n",
    "in our own terms?\n",
    "\n",
    "## 2\n",
    "Besides,\n",
    "it left the humans in the Culture free to take care of the things that really mattered in life,\n",
    "such as [sports, games, romance,] studying dead languages,\n",
    "barbarian societies and impossible problems,\n",
    "and climbing high mountains without the aid of a safety harness.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d6a3dc",
   "metadata": {},
   "source": [
    "This format of the text for STAM is in no way prescribed other than:\n",
    "\n",
    "* It must be plain text\n",
    "* It must be UTF-8 encoded\n",
    "* It should ideally be in Unicode Normalization Form C. (don't worry if this means nothing to you yet)\n",
    "\n",
    "Before we can do anything we need to import the STAM library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b45abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a88536f",
   "metadata": {},
   "source": [
    "Let's add this text resource to an annotation store so we can annotate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f117e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = stam.AnnotationStore(id=\"tutorial\")\n",
    "resource_banks = store.add_resource(id=\"banks\", text=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad080be",
   "metadata": {},
   "source": [
    "Here we passed the text as a string, but it could just as well have been an\n",
    "external text file instead, the filename of which can be passed via the `file=` keyword\n",
    "argument.\n",
    "\n",
    "### Creating an annotation dataset (vocabulary)\n",
    "\n",
    "Our example text is a bit Markdown-like, we have a title header *\"Consider Phlebas\"*, and \n",
    "two subheaders (*1* and *2*) containing one quote from the book each. \n",
    "\n",
    "As our first annotations, let's try to annotate this coarse structure. At this\n",
    "point we're already in need of some vocabulary to express the notions of *title\n",
    "header*, *section header* and *quote*, as STAM does not define any vocabulary.\n",
    "It is up to you to make these choices on how to represent the data.\n",
    "\n",
    "An annotation data set effectively defines an vocabulary. Let's invent our own\n",
    "simple Annotation Data Set that defines the keys and values we use in this\n",
    "tutorial. In our `AnnotationDataSet` We can define a `DataKey` with ID `structuretype`, and have it\n",
    "takes values like `titleheader`, `sectionheader` and `quote`.\n",
    "\n",
    "We can explicitly add the set and the key. We give the dataset a public ID\n",
    "(*tutorial-set*), just as we previously assigned a public ID to both the\n",
    "annotationstore (*tutorial*) and the text resource (*banks*). It is good\n",
    "practise to assign IDs, though you can also let the library auto-generate them\n",
    "for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffa41021",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = store.add_annotationset(\"tutorial-set\")\n",
    "key_structuretype = dataset.add_key(\"structuretype\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ade58c",
   "metadata": {},
   "source": [
    "### The first annotations with text selectors\n",
    "\n",
    "To annotate the title header, we need to select the part of the text where it\n",
    "occurs by finding the offset, which consists of a *begin* and *end* position. STAM\n",
    "follows the same indexing format Python does, in which positions are 0-indexed\n",
    "*unicode character points* (as opposed to (UTF-8) bytes) and where the end is\n",
    "non-inclusive. After some clumsy manual counting on the source text we discover\n",
    "the following coordinates hold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "674600ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert text[1:19] == \"# Consider Phlebas\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bf74f2",
   "metadata": {},
   "source": [
    "And we make the annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a961dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = store.annotate(\n",
    "    target=stam.Selector.textselector(resource_banks, stam.Offset.simple(1,19)),\n",
    "    data={\"id\": \"Data1\", \"key\": key_structuretype, \"value\": \"titleheader\", \"set\": dataset },\n",
    "    id=\"Annotation1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09c8551",
   "metadata": {},
   "source": [
    "A fair amount happened there. We selected a part of the text of\n",
    "`resource_banks` by offset, and associated `AnnotationData` with the annotation\n",
    "saying that the `structuretype` key has the value `titleheader`, both of which\n",
    "we invented as part of our `AnnotationDataSet` with ID `tutorial-set`. Last, we\n",
    "assigned an ID to both the `AnnotationData`, as well as to the `Annotation` as\n",
    "a whole. In this example we reused some of the variables we had created\n",
    "earlier, but we could have also written out in full as shown below: \n",
    "\n",
    "```\n",
    "\n",
    "annotation = store.annotate(\n",
    "    target=stam.Selector.textselector(resource_banks, stam.Offset.simple(1,19)),\n",
    "    data={\"id\": \"Data1\", \"key\": \"structuretype\", \"value\": \"titleheader\", \"set\": \"tutorial-set\" },\n",
    "    id=\"Annotation1\")\n",
    "```\n",
    "\n",
    "This would also have been perfectly fine, and moreover, it would also work fine\n",
    "without us explicitly creating the `AnnotationDataSet` and the key as we did\n",
    "before! Those would have been automatically created on-the-fly for us. The\n",
    "only disadvantage is that under the hood more lookups are needed, so this is\n",
    "slightly less performant than passing python variables.\n",
    "\n",
    "### Inspecting data (1)\n",
    "\n",
    "We can inspect the annotation we just added:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51a74e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation ID:  Annotation1\n",
      "Target text:  # Consider Phlebas\n",
      "Data: \n",
      " - Data ID:  Data1\n",
      "   Data Key:  structuretype\n",
      "   Data Value:  titleheader\n"
     ]
    }
   ],
   "source": [
    "print(\"Annotation ID: \", annotation.id())\n",
    "print(\"Target text: \", str(annotation))\n",
    "print(\"Data: \")\n",
    "for data in annotation.data():\n",
    "    print(\" - Data ID: \", data.id())\n",
    "    print(\"   Data Key: \", data.key().id())\n",
    "    print(\"   Data Value: \", str(data.value()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55086b1e",
   "metadata": {},
   "source": [
    "In the above example, we obtained an `Annotation` instance from the return value of the `annotate()` method. Once any annotation is in the store, we can retrieve it simply by its public ID using the `annotation()` method. An exception will be raised if the ID does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b635c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = store.annotation(\"Annotation1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473b3623",
   "metadata": {},
   "source": [
    "A similar pattern holds for almost all other data structures in the STAM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddfff00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = store.annotationset(\"tutorial-set\")      #AnnotationDataSet\n",
    "resource_banks = store.resource(\"banks\")           #TextResource\n",
    "key_structuretype = dataset.key(\"structuretype\")   #DataKey\n",
    "data = dataset.annotationdata(\"Data1\")             #AnnotationData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33631c4",
   "metadata": {},
   "source": [
    "### Annotating via `find_text()`\n",
    "\n",
    "We now continue by adding annotations for the two section headers. Counting offsets\n",
    "manually is rather cumbersome, so we use the `find_text()` method on `TextResource` to find our target for annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3f08f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text ## 1 found at 44:48\n"
     ]
    }
   ],
   "source": [
    "results = resource_banks.find_text(\"## 1\")\n",
    "section1 = results[0]\n",
    "print(f\"Text {str(section1)} found at {section1.begin()}:{section1.end()}\")\n",
    "\n",
    "annotation = store.annotate(\n",
    "    target=stam.Selector.textselector(resource_banks, section1.offset()),\n",
    "    data={\"id\": \"Data2\", \"key\": \"structuretype\", \"value\": \"sectionheader\", \"set\": \"tutorial-set\" },\n",
    "    id=\"Annotation2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a584d8",
   "metadata": {},
   "source": [
    "The `find_text()` method returns a list of `TextSelection` instances. These\n",
    "carry an `Offset` which is returned by the `offset()` method. Hooray, no more\n",
    "manual counting!\n",
    "\n",
    "We do the same for the last header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83ee736f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text ## 2 found at 365:369\n"
     ]
    }
   ],
   "source": [
    "results = resource_banks.find_text(\"## 2\")\n",
    "section2 = results[0]\n",
    "print(f\"Text {str(section2)} found at {section2.begin()}:{section2.end()}\")\n",
    "\n",
    "annotation = store.annotate(\n",
    "    target=stam.Selector.textselector(resource_banks, section2.offset()),\n",
    "    data={\"id\": \"Data2\", \"key\": \"structuretype\", \"value\": \"sectionheader\", \"set\": \"tutorial-set\" },\n",
    "    id=\"Annotation3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14a1d53",
   "metadata": {},
   "source": [
    "### Inspecting data (2)\n",
    "\n",
    "In the previous code the attentive reader may have noted that we are reusing the `Data2` ID\n",
    "rather than introducing a new `Data3` ID, because the data for both\n",
    "`Annotation2` and `Annotation3` is in fact, identical.\n",
    "\n",
    "This is an important feature of STAM; annotations and their data are\n",
    "decoupled precisely because the data may be referenced by multiple annotations, and\n",
    "if that's the case, we only want to keep the data in memory once. We don't want\n",
    "a copy for every annotation. Say we have `AnnotationData` with key\n",
    "`structuretype` and value `word`, and use that to tag all words in the\n",
    "text, then it would be a huge amount of redundancy if there was no such\n",
    "decoupling between data and annotations. The fact that they all share the same data, also\n",
    "enables us to quickly look up all those annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f064446",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotationdata = dataset.find_data(\"structuretype\", \"sectionheader\")\n",
    "for annotation in annotationdata.annotations():\n",
    "    assert annotation.id() in (\"Annotation2\",\"Annotation3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28556796",
   "metadata": {},
   "source": [
    "### Annotations via text selections\n",
    "\n",
    "Now we annotate the quotes themselves. The first one starts after the first\n",
    "subheader (Annotation2) and ends just before the next subheader (Annotation3).\n",
    "That would include some ugly leading and trailing whitespace/newlines, though.\n",
    "We use the `textselection()` method to obtain a textselection to our computed\n",
    "offset and subsequently strip the whitespace using the `strip_text()` method,\n",
    "effectively shrinking our textselection a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "693e0483",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote1_selection = resource_banks.textselection(stam.Offset.simple(section1.end(), section2.begin() - 1)).strip_text(\" \\t\\r\\n\")\n",
    "quote1 = store.annotate(\n",
    "    target=stam.Selector.textselector(resource_banks, quote1_selection.offset()),\n",
    "    data={\"id\": \"Data3\", \"key\": \"structuretype\", \"value\": \"quote\", \"set\": \"tutorial-set\" },\n",
    "    id=\"AnnotationQuote1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d757a5da",
   "metadata": {},
   "source": [
    "The second quote goes until the end of the text, which we can retrieve using\n",
    "the `textlen()` method. This method is preferred over doing things in native\n",
    "python like `len(str(banks))` because it is way more efficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "057a76a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote2_selection = resource_banks.textselection(stam.Offset.simple(section2.end(), resource_banks.textlen())).strip_text(\" \\t\\r\\n\")\n",
    "quote2 = store.annotate(\n",
    "    target=stam.Selector.textselector(resource_banks, quote2_selection.offset()),\n",
    "    data={\"id\": \"Data3\", \"set\": \"tutorial-set\"},\n",
    "    id=\"AnnotationQuote2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b3a9a4",
   "metadata": {},
   "source": [
    "In this example we also show that, since we reference existing\n",
    "`AnnotationData`, just specifying the ID and the set suffices. Or even shorter and better, you could pass\n",
    "a variable that is an instance of `AnnotationData`.\n",
    "\n",
    "There is another structural type we could annotate: the lines with\n",
    "corresponding line numbers. This is easy to do by splitting the text on\n",
    "newlines, for which we use the method `split_text()` on `TextResource`. As you\n",
    "see, various Python methods such as `split()`, `strip()`, `find()` have\n",
    "counterparts in STAM that have a `*_text()` suffix and which return\n",
    "`TextSelection` instances and carry offset information:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c7a6d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1: \n",
      "Line 2: # Consider Phlebas\n",
      "Line 3: $ author=Iain M. Banks\n",
      "Line 4: \n",
      "Line 5: ## 1\n",
      "Line 6: Everything about us,\n",
      "Line 7: everything around us,\n",
      "Line 8: everything we know [and can know of] is composed ultimately of patterns of nothing;\n",
      "Line 9: thatâ€™s the bottom line, the final truth.\n",
      "Line 10: \n",
      "Line 11: So where we find we have any control over those patterns,\n",
      "Line 12: why not make the most elegant ones, the most enjoyable and good ones,\n",
      "Line 13: in our own terms?\n",
      "Line 14: \n",
      "Line 15: ## 2\n",
      "Line 16: Besides,\n",
      "Line 17: it left the humans in the Culture free to take care of the things that really mattered in life,\n",
      "Line 18: such as [sports, games, romance,] studying dead languages,\n",
      "Line 19: barbarian societies and impossible problems,\n",
      "Line 20: and climbing high mountains without the aid of a safety harness.\n",
      "Line 21: \n"
     ]
    }
   ],
   "source": [
    "for linenr, line in enumerate(resource_banks.split_text(\"\\n\")):\n",
    "    linenr += 1      #make it 1-indexed as is customary for line numbers\n",
    "    print(f\"Line {linenr}: {str(line)}\")\n",
    "    store.annotate(\n",
    "        target=stam.Selector.textselector(resource_banks, line.offset()),\n",
    "        data=[ \n",
    "            {\"id\": \"Data4\", \"key\": \"structuretype\", \"value\": \"line\", \"set\": \"tutorial-set\" },\n",
    "            {\"id\": f\"DataLine{linenr}\", \"key\": \"linenr\", \"value\": linenr, \"set\": \"tutorial-set\" }\n",
    "        ],\n",
    "        id=f\"AnnotationLine{linenr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e44e93",
   "metadata": {},
   "source": [
    "In this example we also extended our vocabulary on-the-fly with a new field `linenr`. All line annotations carry two `AnnotationData` elements. Remember we an easily retrieve the data and any annotations on it with `find_data()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82d3b6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything we know [and can know of] is composed ultimately of patterns of nothing;\n"
     ]
    }
   ],
   "source": [
    "annotationdata = dataset.find_data(\"linenr\", 8)\n",
    "assert annotationdata is not None\n",
    "line8 = annotationdata.annotations()[0]\n",
    "print(str(line8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a5f89",
   "metadata": {},
   "source": [
    "When annotating, we don't have to work with the resource as a whole but can\n",
    "also start relative from any text selection we have.  Let's take line eight and\n",
    "annotate the first word of it (*\"everything\"*) manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2308520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text selection spans: 92:102\n"
     ]
    }
   ],
   "source": [
    "line8_textselection = line8.textselections()[0] #there could be multiple, but in our cases thus-far we only have one\n",
    "firstword = line8_textselection.textselection(stam.Offset.simple(0,10))  #we make a textselection on a textselection\n",
    "\n",
    "#internally, the text selection will always use absolute coordinates for the resource:\n",
    "print(f\"Text selection spans: {firstword.begin()}:{firstword.end()}\")\n",
    "\n",
    "annotation = store.annotate(\n",
    "    target=stam.Selector.textselector(resource_banks, firstword.offset()),\n",
    "    data= {\"key\": \"structuretype\", \"value\": \"word\", \"set\": \"tutorial-set\" },\n",
    "    id=f\"AnnotationLine8Word1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b233eae",
   "metadata": {},
   "source": [
    "### Converting offsets\n",
    "\n",
    "We know the first word of line eight is also part of quote one, for which we already made an annotation (`AnnotationQuote1`) before.\n",
    "Say we are interested in knowing *where* in quote one the first word of line eight is, we can now easily compute so as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a30917c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset in quote one: <stam.Cursor object at 0x7f4e121c6640>:<stam.Cursor object at 0x7f4e121c6640>\n"
     ]
    }
   ],
   "source": [
    "offset = firstword.relative_offset(quote1_selection)\n",
    "print(f\"Offset in quote one: {offset.begin()}:{offset.end()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e429a43b",
   "metadata": {},
   "source": [
    "While we are at it, another conversion option that may come handy when working\n",
    "on a lower-level is the conversion from/to UTF-8 byte offsets. Both STAM and\n",
    "Python use unicode character points. Internally STAM already maps these to\n",
    "UTF-8 byte offsets for things like text slicing, but if you need this\n",
    "information you can extract it explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f87e805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byte offset: 92:102\n"
     ]
    }
   ],
   "source": [
    "beginbyte = resource_banks.utf8byte(firstword.begin())\n",
    "endbyte = resource_banks.utf8byte(firstword.end())\n",
    "print(f\"Byte offset: {beginbyte}:{endbyte}\")\n",
    "\n",
    "#and back again:\n",
    "beginpos = resource_banks.utf8byte_to_charpos(beginbyte)\n",
    "endpos = resource_banks.utf8byte_to_charpos(endbyte)\n",
    "\n",
    "assert beginpos == firstword.begin()\n",
    "assert endpos == firstword.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da98e965",
   "metadata": {},
   "source": [
    "In this case they happen to be equal because we're basically only using ASCII\n",
    "in our text, but as soon as you deal with multibyte characters (diacritics,\n",
    "other scripts, etc), they will not!\n",
    "\n",
    "### Tokenisation via regular expressions\n",
    "\n",
    "What else can we annotate? We can mark all individual words or tokens,\n",
    "effectively performing simple *tokenisation*. For this, we will use the regular\n",
    "expression search that is built into the STAM library, `find_text_regex()`. The\n",
    "regular expressions follow [Rust's regular expression\n",
    "syntax](https://docs.rs/regex/latest/regex/#syntax) which may differ slightly\n",
    "from Python's native implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bea05e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expressions = [\n",
    "    r\"\\w+(?:[-_]\\w+)*\", #this detects words,possibly with hyphens or underscores as part of it\n",
    "    r\"[\\.\\?,/]+\", #this detects a variety of punctuation\n",
    "    r\"[0-9]+(?:[,\\.][0-9]+)\", #this detects numbers, possibly with a fractional part\n",
    "]\n",
    "structuretypes = [\"word\", \"punctuation\", \"number\"]\n",
    "\n",
    "for i, matchresult in enumerate(resource_banks.find_text_regex(expressions)):\n",
    "    #(we only have one textselection per match, but an regular expression may result in multiple textselections if capture groups are used)\n",
    "    textselection = matchresult['textselections'][0]\n",
    "    store.annotate(\n",
    "        target=stam.Selector.textselector(resource_banks, line.offset()),\n",
    "        data=[ \n",
    "            {\"key\": \"structuretype\", \"value\": structuretypes[matchresult['expression_index']], \"set\": \"tutorial-set\" }\n",
    "        ],\n",
    "        id=f\"AnnotationToken{i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275a37c2",
   "metadata": {},
   "source": [
    "In this code, each `matchresult` tracks which of the three expressions was\n",
    "matches, in `matchresult['expression_index']`. We conveniently use that\n",
    "information to tie new values for `structuretype`, all of which will be added\n",
    "to our vocabulary (`AnnotationDataSet`) on-the-fly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def7193b",
   "metadata": {},
   "source": [
    "### Annotating Metadata\n",
    "\n",
    "Thus-far we have only seen annotations directly on the text, using\n",
    "`Selector.textselector()`, but STAM has various other selectors. Users may\n",
    "appreciate if you add a bit of metadata about your texts. In STAM, these are\n",
    "annotations that point at the resource as a whole using a\n",
    "`Selector.resourceselector()`, rather than at the text specifically. We add one\n",
    "metadata annotation with various new fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae1ab36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = store.annotate(\n",
    "    target=stam.Selector.resourceselector(resource_banks),\n",
    "    data=[ \n",
    "        {\"key\": \"name\", \"value\": \"Culture quotes from Iain Banks\", \"set\": \"tutorial-set\" },\n",
    "        {\"key\": \"compiler\", \"value\": \"Dirk Roorda\", \"set\": \"tutorial-set\" },\n",
    "        {\"key\": \"source\", \"value\": \"https://www.goodreads.com/work/quotes/14366-consider-phlebas\", \"set\": \"tutorial-set\" },\n",
    "        {\"key\": \"version\", \"value\": \"0.2\", \"set\": \"tutorial-set\" },\n",
    "    ],\n",
    "    id=\"Metadata1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f8f90",
   "metadata": {},
   "source": [
    "Similarly, we could annotate an `AnnotationDataSet` (our vocabulary) with metadata, using a `Selector.datasetselector()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc99264",
   "metadata": {},
   "source": [
    "## Navigating through your data\n",
    "\n",
    "### Basic iterating and counting\n",
    "\n",
    "If you followed all of the previous section, we now have a fair amount of annotations. In fact, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fc7c8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 annotations\n",
      "1 resource\n",
      "1 annotation dataset\n",
      "6 datakeys in our dataset\n",
      "30 annotationdata instances in our dataset\n"
     ]
    }
   ],
   "source": [
    "print(f\"{store.annotations_len()} annotations\")\n",
    "print(f\"{store.resources_len()} resource\")\n",
    "print(f\"{store.annotationsets_len()} annotation dataset\")\n",
    "print(f\"{dataset.keys_len()} datakeys in our dataset\")\n",
    "print(f\"{dataset.data_len()} annotationdata instances in our dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cddbe8a",
   "metadata": {},
   "source": [
    "If we zoom in on the annotation data in our annotation dataset, we can extract some interesting frequency statistics right away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8d0e2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structuretype: titleheader occurs in 1 annotation(s)\n",
      "structuretype: sectionheader occurs in 2 annotation(s)\n",
      "structuretype: quote occurs in 2 annotation(s)\n",
      "structuretype: line occurs in 21 annotation(s)\n",
      "linenr: 1 occurs in 1 annotation(s)\n",
      "linenr: 2 occurs in 1 annotation(s)\n",
      "linenr: 3 occurs in 1 annotation(s)\n",
      "linenr: 4 occurs in 1 annotation(s)\n",
      "linenr: 5 occurs in 1 annotation(s)\n",
      "linenr: 6 occurs in 1 annotation(s)\n",
      "linenr: 7 occurs in 1 annotation(s)\n",
      "linenr: 8 occurs in 1 annotation(s)\n",
      "linenr: 9 occurs in 1 annotation(s)\n",
      "linenr: 10 occurs in 1 annotation(s)\n",
      "linenr: 11 occurs in 1 annotation(s)\n",
      "linenr: 12 occurs in 1 annotation(s)\n",
      "linenr: 13 occurs in 1 annotation(s)\n",
      "linenr: 14 occurs in 1 annotation(s)\n",
      "linenr: 15 occurs in 1 annotation(s)\n",
      "linenr: 16 occurs in 1 annotation(s)\n",
      "linenr: 17 occurs in 1 annotation(s)\n",
      "linenr: 18 occurs in 1 annotation(s)\n",
      "linenr: 19 occurs in 1 annotation(s)\n",
      "linenr: 20 occurs in 1 annotation(s)\n",
      "linenr: 21 occurs in 1 annotation(s)\n",
      "structuretype: word occurs in 109 annotation(s)\n",
      "name: Culture quotes from Iain Banks occurs in 1 annotation(s)\n",
      "compiler: Dirk Roorda occurs in 1 annotation(s)\n",
      "source: https://www.goodreads.com/work/quotes/14366-consider-phlebas occurs in 1 annotation(s)\n",
      "version: 0.2 occurs in 1 annotation(s)\n"
     ]
    }
   ],
   "source": [
    "for data in dataset:\n",
    "    count = data.annotations_len()\n",
    "    print(f\"{data.key()}: {data.value()} occurs in {count} annotation(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675d2442",
   "metadata": {},
   "source": [
    "We can also aggregate only by key, although that is slightly less informative for our example case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7df1af54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structuretype occurs in 135 annotation(s)\n",
      "linenr occurs in 21 annotation(s)\n",
      "name occurs in 1 annotation(s)\n",
      "compiler occurs in 1 annotation(s)\n",
      "source occurs in 1 annotation(s)\n",
      "version occurs in 1 annotation(s)\n"
     ]
    }
   ],
   "source": [
    "for key in dataset.keys():\n",
    "    count = key.annotations_count()   #this one is called _count instead of _len because it is not instantaneous like the other one\n",
    "    print(f\"{key} occurs in {count} annotation(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa471847",
   "metadata": {},
   "source": [
    "Just like above we iterated over the annotation dataset, we can also iterate over various things in the `AnnotationStore`. Let's write a small script that simply prints out most of the things in our store. At this point though, the output will get a bit verbose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62830d7d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"Datasets:\")\n",
    "for dataset in store.annotationsets():\n",
    "    print(f\" - ID: {dataset.id()}\")\n",
    "\n",
    "print(\"Resources:\")\n",
    "for resource in store.resources():\n",
    "    print(f\" - ID: {resource.id()}\")\n",
    "    print(f\" - Text length: {resource.textlen()}\")\n",
    "\n",
    "print(\"Annotations:\")\n",
    "for annotation in store.annotations():\n",
    "    print(f\" - ID: {annotation.id()}\")\n",
    "    print(f\"   Data:\")\n",
    "    for data in annotation:\n",
    "        print(f\"    - ID:  {data.id()}\")\n",
    "        print(f\"    - Set: {data.annotationset().id()}\")\n",
    "        print(f\"    - Key: {data.key()}\")\n",
    "        print(f\"    - Value: {data.value()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d8c85",
   "metadata": {},
   "source": [
    "## Saving and loading data\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
